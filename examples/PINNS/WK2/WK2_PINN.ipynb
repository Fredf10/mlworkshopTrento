{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pysically informed neural networks - The Two Element Windkessel model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here we will implement the two element Windkessel in a Pysically Informed Neural Network. The model is affected by the parameters R and C, also known as total vascular resitance and total arterial compliance. The equation describing the model is the following:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\mathrm{d}p}{\\mathrm{dt}} = \\frac{Q_{\\mathrm{in}}}{C} - \\frac{p}{R C} \n",
    "\\end{equation*}\n",
    "\n",
    "The compliant vessels of the systemic circulation are filled and stressed by blood ejected in systole from the heart. During diastole the elatic recoil of the vessel walls smoothes the blood flow in the vessels and keeps the circulation in motion even when the heart is not ejecting blood. This effect is named after an air chamber used to produce smooth water flows for fire fighting in the past. See the Figure below for a simple illustration. \n",
    "\n",
    "<img src = \"http://folk.ntnu.no/nikolalb/ML_ws/Windkessel_effect.svg\" width=600>\n",
    "\n",
    "The model computes the blood pressure waveform $P_{ao}(t)$ (used interchangeably with $p$)* according to the imposed inflow $Q_{\\mathrm{in}}$, and the specified parameters $R$ and $C$. If we use this model to produce data and then build a PINN loss function implementing the equation above, taking the input flow and a few points sampled from the model produced pressure function. \n",
    "\n",
    "In the code below, $f$ refers to the sum:\n",
    "\n",
    "\\begin{equation*}\n",
    "f = \\frac{\\mathrm{d}p}{\\mathrm{dt}} - \\frac{Q_{\\mathrm{in}}}{C} + \\frac{p}{R C}\n",
    "\\end{equation*}\n",
    "\n",
    "which ideally should be equal to zero, and must be minimized to obey the physics of the problem. $u$ refers to our variable of interest, which here is $p$ used interchangeably with $P_{ao}$. \n",
    "\n",
    "Problem 1:\n",
    "- Tune the hyperparameters number of nodes, layers, epochs, training rate, but also the number of pressure training points, number of flow points, and try to get a good fit. Can you implement an ordinary neural network which can learn the pressure? Which can you get to perform best?\n",
    "\n",
    "For this problem a gaussian inflow is prescribed, you can also attempt with a real input flow from the file \"./Inflow/pqdata.mat\", and see how this affects the results. Use the functions \"import data\" and \"periodic_func_from_data\" to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as scint\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#==================================================\n",
    "# Set up a 2 element Windkessel model for production of data\n",
    "#==================================================\n",
    "\n",
    "class WK2():\n",
    "    def __init__(self, pars):\n",
    "        self.R_sys = pars[\"R_sys\"]\n",
    "        self.C_sa = pars[\"C_sa\"]\n",
    "    \n",
    "    def gaussian_flow(self,t):\n",
    "        tau = np.mod(t,1.0)\n",
    "        gaussian = 450.0*np.exp(-(tau-0.2)**2 / (0.09)**2)\n",
    "        return gaussian\n",
    "    \n",
    "    def rhs(self, t, u):\n",
    "        P_ao = u[0]\n",
    "        tau = np.mod(t,1.0)\n",
    "        Q_lvao = self.gaussian_flow(tau)\n",
    "        Q_aosv = P_ao/self.R_sys\n",
    "        \n",
    "        der_P_ao = (Q_lvao - Q_aosv)/self.C_sa\n",
    "        der_u = [der_P_ao]\n",
    "        \n",
    "        return der_u\n",
    "\n",
    "    def calc_all(self, t, u):\n",
    "        P_ao = u[0]\n",
    "        tau = np.mod(t,1.0)\n",
    "        Q_lvao = self.gaussian_flow(tau)\n",
    "        Q_aosv =  P_ao/self.R_sys\n",
    "        \n",
    "        all_vars = locals()\n",
    "        del all_vars[\"self\"]  \n",
    "        del all_vars[\"u\"]\n",
    "\n",
    "        der_P_ao = (Q_lvao - Q_aosv)/self.C_sa\n",
    "        der_u = [der_P_ao]\n",
    "\n",
    "        return der_u, all_vars\n",
    "\n",
    "def periodic_func_from_data(self,x_data, y_data, n_modes=40):\n",
    "    dx = x_data[1]-x_data[0]\n",
    "    N = len(self.t)\n",
    "    # Normalization by /N and symmetry\n",
    "    Y_fft = np.fft.fft(y_data)/N \n",
    "    Y_fft[1:] *= 2\n",
    "    fft_freq = np.fft.fftfreq(N, d=dx)\n",
    "\n",
    "    def periodic_func(x):\n",
    "        y_trig = np.zeros_like(x)\n",
    "        for kk in range(n_modes):\n",
    "            y_trig += np.real(Y_fft[kk]*np.exp(2j*np.pi * fft_freq[kk] * x))\n",
    "        return y_trig\n",
    "    \n",
    "    return periodic_func\n",
    "    \n",
    "def import_data(filepath):\n",
    "\n",
    "    data = sio.loadmat(filepath)\n",
    "    q = data[\"q\"]\n",
    "    p = data[\"p\"]\n",
    "    p=p.flatten()  # convert array to vector\n",
    "    q=q.flatten()\n",
    "    N = len(q)\n",
    "\n",
    "    t= data[\"t\"]\n",
    "    t=t.flatten()\n",
    "    dt = t[1]-t[0]\n",
    "        \n",
    "    return  p, q, t, dt, N\n",
    "    \n",
    "def get1D_data(N, showPlots=True):\n",
    "    #Calculate data\n",
    "    P_ao_0 = 100.0\n",
    "    u0 = [P_ao_0]\n",
    "    \n",
    "    Parameters = dict(R_sys=1.5,C_sa=1.5)\n",
    "    wkmod = WK2(Parameters)\n",
    "    Ncycles = 20\n",
    "    tmax = Ncycles*1.0 #Ncycles\n",
    "    t_eval_vals = np.linspace(0.0, tmax, N*Ncycles)\n",
    "    \n",
    "    ################################################################\n",
    "    ###################  solve_ivp routine  ########################\n",
    "    ################################################################ \n",
    "    sol = scint.solve_ivp(wkmod.rhs, (0.0, tmax), u0, max_step=0.01, t_eval=t_eval_vals)\n",
    "    _, all_vars = wkmod.calc_all(sol.t, sol.y)\n",
    "    P_ao_fin_cyc = all_vars[\"P_ao\"][int((Ncycles-1)*N):]\n",
    "    t_fin = all_vars[\"t\"][0:N]\n",
    "    q_lvao = wkmod.gaussian_flow(t_fin)\n",
    "    \n",
    "    #P_np, P_q_np, integrand_q_array = calcDeltaP(t_in, integrand_q, P_in=0)\n",
    "    if showPlots:\n",
    "        plt.figure()\n",
    "        plt.plot(t_fin, P_ao_fin_cyc)\n",
    "        plt.legend([\"P_ao\"])\n",
    "        #plt.plot(x_np, linearTapering_np(x_np, R0, Rmin, l))\n",
    "        plt.xlabel(\"t [s]\")\n",
    "        plt.ylabel(\"P [mmHg]\")\n",
    "        plt.title(\"Pressure curve for data sampling\")\n",
    "        plt.show()\n",
    "    \n",
    "    return t_fin, P_ao_fin_cyc, q_lvao, wkmod.R_sys, wkmod.C_sa\n",
    "\n",
    "#x_np, r_np, P_np, P_f_np, P_c_np, integrand_f_array, integrand_c_array = get1D_data(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Functions for setting up the neural network\n",
    "#====================================\n",
    "\n",
    "def net_u(t):\n",
    "    u = neural_net(t, weights, biases)\n",
    "    return u\n",
    "#===================================================\n",
    "\n",
    "def net_f_WK(t, Q, R, C):\n",
    "    \n",
    "    u = net_u(t)\n",
    "    \n",
    "    u_t = tf.gradients(u, t)\n",
    "    \n",
    "    f =  u_t + u/(R*C) - Q/C\n",
    "    \n",
    "    return f\n",
    "#===================================================\n",
    "\n",
    "def initialize_NN(layers):        \n",
    "    weights = []\n",
    "    biases = []\n",
    "    num_layers = len(layers) \n",
    "    for l in range(0, num_layers - 1):\n",
    "        W = xavier_init(size=[layers[l], layers[l+1]])\n",
    "        #W = tf.Variable(tf.random_normal([layers[l], layers[l+1]], stddev=10))\n",
    "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "        weights.append(W)\n",
    "        biases.append(b)        \n",
    "    return weights, biases\n",
    "#===================================================\n",
    "  \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]        \n",
    "    xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "#===================================================\n",
    "\n",
    "def neural_net(X, weights, biases):\n",
    "    num_layers = len(weights) + 1\n",
    "    \n",
    "    H = 2.0*(X - lb)/(ub - lb) - 1.0\n",
    "    for l in range(0, num_layers - 2):\n",
    "        W = weights[l]\n",
    "        b = biases[l]\n",
    "        H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "    W = weights[-1]\n",
    "    b = biases[-1]\n",
    "    Y = tf.add(tf.matmul(H, W), b)\n",
    "    return Y\n",
    "#===================================================\n",
    "\n",
    "def callback(loss):\n",
    "    print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "#===================================================\n",
    "# load data\n",
    "#===================================================\n",
    "N = 1001 # total number of x, P values\n",
    "N_train = 10 # number of training points\n",
    "N_train_f = 200 # number of training points for f, i.e., input flow term and pressure term\n",
    "\n",
    "t, P_data, Q_data, R, C = get1D_data(N, showPlots=True)\n",
    "\n",
    "#===================================================\n",
    "# set parameters for neural network and training\n",
    "#===================================================\n",
    "layers = [1, 3, 1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#===================================================\n",
    "# turn 1D array into 2D array of shape (N, 1)\n",
    "#===================================================\n",
    "t = t[:, np.newaxis]\n",
    "P_data = P_data[:, np.newaxis]\n",
    "Q_data = Q_data[:, np.newaxis]\n",
    "#===================================================\n",
    "# sample random points for training\n",
    "#===================================================\n",
    "idx = np.random.choice(t.shape[0], N_train, replace=False)\n",
    "idx_q = np.random.choice(t.shape[0], N_train_f, replace=False)\n",
    "t_train = t[idx]\n",
    "t_f_train = t[idx_q]#t[idx]\n",
    "P_train = P_data[idx]\n",
    "#t_train = t[0:1,0:1]\n",
    "#q_train = P[0:1,0:1]\n",
    "\n",
    "q_train = Q_data[idx_q]\n",
    "#q_train = Q_data[idx]\n",
    "#===================================================\n",
    "# Set up placeholder for inputs and outputs\n",
    "#===================================================\n",
    "C_tf = tf.constant(C)\n",
    "R_tf = tf.constant(R)\n",
    "\n",
    "t_tf = tf.placeholder(tf.float32, shape=[None, t.shape[1]], name='t')\n",
    "t_f_tf = tf.placeholder(tf.float32, shape=[None, t.shape[1]], name='t')\n",
    "P_tf = tf.placeholder(tf.float32, shape=[None, P_data.shape[1]], name='P')\n",
    "\n",
    "q_tf = tf.placeholder(tf.float32, shape=[None, Q_data.shape[1]], name='Q')\n",
    "#===================================================\n",
    "# initialize neural net and f functions\n",
    "#===================================================\n",
    "lb = t.min(0)\n",
    "ub = t.max(0)\n",
    "weights, biases = initialize_NN(layers)\n",
    "\n",
    "P_pred = net_u(t_tf)\n",
    "f_pred = net_f_WK(t_f_tf, q_tf, C_tf, R_tf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================\n",
    "# plot y_pred before training\n",
    "#===================================================\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # initialize variables\n",
    "    P_pred_init = sess.run(P_pred, feed_dict = {t_tf:t_train})\n",
    "plt.figure()\n",
    "plt.plot(t.flatten(), P_data.flatten(), label = \"Data\")\n",
    "plt.plot(t_train.flatten(), P_train.flatten(), 'o', label=\"Training points\")\n",
    "plt.plot(t_train.flatten(), P_pred_init.flatten(), label = \"Init\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#===========================================================#\n",
    "# train the model using PINNS and GradientDescentOptimizer  #\n",
    "#===========================================================#\n",
    "batch_size = N_train\n",
    "loss = tf.reduce_mean(tf.square(P_tf - P_pred)) + tf.reduce_mean(tf.square(f_pred))\n",
    "learning_rate = 0.002\n",
    "#learning_rate_late = 0.5\n",
    "epochs = 30000\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "print_every_N_batch = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # initialize variables\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        _, c = sess.run([optimiser, loss], \n",
    "                     feed_dict={t_tf: t_train, P_tf: P_train, \n",
    "                                t_f_tf: t_f_train, q_tf:q_train})\n",
    "        avg_cost += c\n",
    "        if epoch % print_every_N_batch == 0:\n",
    "            print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.6f}\".format(avg_cost))\n",
    "\n",
    "    P_result = sess.run(P_pred, feed_dict = {t_tf:t})\n",
    "    plt.figure()\n",
    "    plt.plot(t.flatten(), P_data.flatten())\n",
    "    plt.plot(t_train.flatten(), P_train.flatten(), 'o')\n",
    "    plt.plot(t.flatten(), P_result.flatten(), 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#===========================================================#\n",
    "# train the model using PINNS and ScipyOptimizerInterface   #\n",
    "#===========================================================#\n",
    "\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss, \n",
    "                                                   method = 'L-BFGS-B', \n",
    "                                                   options = {'maxiter': 500,\n",
    "                                                              'maxfun': 50000,\n",
    "                                                              'maxcor': 50,\n",
    "                                                              'maxls': 50,\n",
    "                                                              'ftol' : 1.0 * np.finfo(float).eps})\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf_dict = {t_tf: t_train, P_tf: P_train, \n",
    "                             t_f_tf: t_f_train, q_tf:q_train}\n",
    "    optimizer.minimize(sess, \n",
    "                       feed_dict = tf_dict,         \n",
    "                       fetches = [loss], \n",
    "                       loss_callback = callback)\n",
    "\n",
    "    P_result = sess.run(P_pred, feed_dict = {t_tf: t})\n",
    "    plt.figure()\n",
    "    plt.plot(t.flatten(), P_data.flatten(),'b')\n",
    "    plt.plot(t_train.flatten(), P_train.flatten(), 'yo')\n",
    "    plt.plot(t.flatten(), P_result.flatten(), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
